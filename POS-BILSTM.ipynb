{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMcxjFBoQo/roeE6jCvvZ+l"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ixPjrCXSSQ2p","executionInfo":{"status":"ok","timestamp":1763844762308,"user_tz":-180,"elapsed":760836,"user":{"displayName":"Mouad Hamadou","userId":"05595019970978432021"}},"outputId":"8404ff21-c4a0-4970-8689-4faa922d9ca2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Using device: cpu\n","#train sentences: 6075\n","#dev sentences: 909\n","#test sentences: 680\n","Vocab size: 21917\n","Num tags: 18\n","Tags: {'<PAD_TAG>': 0, 'ADJ': 1, 'ADP': 2, 'ADV': 3, 'AUX': 4, 'CCONJ': 5, 'DET': 6, 'INTJ': 7, 'NOUN': 8, 'NUM': 9, 'PART': 10, 'PRON': 11, 'PROPN': 12, 'PUNCT': 13, 'SCONJ': 14, 'SYM': 15, 'VERB': 16, 'X': 17}\n","Epoch 1: train_loss=0.9562, dev_acc=0.8173\n","Epoch 2: train_loss=0.4176, dev_acc=0.8729\n","Epoch 3: train_loss=0.2734, dev_acc=0.8942\n","Epoch 4: train_loss=0.1894, dev_acc=0.9033\n","Epoch 5: train_loss=0.1304, dev_acc=0.9115\n","Test accuracy (BiLSTM): 0.9172091706764789\n","Example prediction: [('سوريا', 'X'), ('تستقبل', 'VERB'), ('وفدا', 'NOUN'), ('رسميا', 'ADJ'), ('.', 'PUNCT')]\n"]}],"source":["# ======================================\n","# BiLSTM POS Tagger for Arabic (PyTorch)\n","# ======================================\n","\n","!pip install -q torch\n","\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset, DataLoader\n","from collections import Counter\n","import numpy as np\n","\n","DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(\"Using device:\", DEVICE)\n","\n","TRAIN_PATH = \"train.conll\"\n","DEV_PATH   = \"dev.conll\"\n","TEST_PATH  = \"test.conll\"\n","\n","PAD_WORD = \"<PAD>\"\n","UNK_WORD = \"<UNK>\"\n","PAD_TAG  = \"<PAD_TAG>\"\n","\n","\n","# ---------------------------\n","# 1) Read .conll data\n","# ---------------------------\n","def read_conll(path):\n","    sentences = []\n","    tokens = []\n","    tags = []\n","    with open(path, encoding=\"utf-8\") as f:\n","        for line in f:\n","            line = line.strip()\n","            if not line:\n","                if tokens:\n","                    sentences.append((tokens, tags))\n","                    tokens, tags = [], []\n","                continue\n","            parts = line.split(\"\\t\")\n","            if len(parts) != 2:\n","                continue\n","            w, t = parts\n","            tokens.append(w)\n","            tags.append(t)\n","    if tokens:\n","        sentences.append((tokens, tags))\n","    return sentences\n","\n","train_sents = read_conll(TRAIN_PATH)\n","dev_sents   = read_conll(DEV_PATH)\n","test_sents  = read_conll(TEST_PATH)\n","\n","print(\"#train sentences:\", len(train_sents))\n","print(\"#dev sentences:\", len(dev_sents))\n","print(\"#test sentences:\", len(test_sents))\n","\n","\n","# ---------------------------\n","# 2) Build vocabularies\n","# ---------------------------\n","word_freq = Counter()\n","tag_set = set()\n","\n","for tokens, tags in train_sents:\n","    word_freq.update(tokens)\n","    tag_set.update(tags)\n","\n","# keep all words with freq >= 1 (you can set 2 if you want)\n","min_freq = 1\n","words = [w for w, c in word_freq.items() if c >= min_freq]\n","\n","word2id = {PAD_WORD: 0, UNK_WORD: 1}\n","for w in words:\n","    word2id[w] = len(word2id)\n","\n","id2word = {i: w for w, i in word2id.items()}\n","\n","tag2id = {PAD_TAG: 0}\n","for t in sorted(tag_set):\n","    tag2id[t] = len(tag2id)\n","id2tag = {i: t for t, i in tag2id.items()}\n","\n","vocab_size = len(word2id)\n","num_tags = len(tag2id)\n","pad_word_id = word2id[PAD_WORD]\n","unk_word_id = word2id[UNK_WORD]\n","pad_tag_id  = tag2id[PAD_TAG]\n","\n","print(\"Vocab size:\", vocab_size)\n","print(\"Num tags:\", num_tags)\n","print(\"Tags:\", tag2id)\n","\n","\n","# ---------------------------\n","# 3) Dataset & DataLoader\n","# ---------------------------\n","class PosDataset(Dataset):\n","    def __init__(self, sentences, word2id, tag2id):\n","        self.data = []\n","        for tokens, tags in sentences:\n","            w_ids = [word2id.get(w, unk_word_id) for w in tokens]\n","            t_ids = [tag2id[t] for t in tags]\n","            self.data.append((w_ids, t_ids))\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, idx):\n","        return self.data[idx]\n","\n","def collate_fn(batch):\n","    # batch: list of (w_ids, t_ids)\n","    lengths = [len(x[0]) for x in batch]\n","    max_len = max(lengths)\n","\n","    batch_words = []\n","    batch_tags = []\n","\n","    for (w_ids, t_ids) in batch:\n","        # pad words\n","        w_padded = w_ids + [pad_word_id] * (max_len - len(w_ids))\n","        t_padded = t_ids + [pad_tag_id] * (max_len - len(t_ids))\n","        batch_words.append(w_padded)\n","        batch_tags.append(t_padded)\n","\n","    batch_words = torch.tensor(batch_words, dtype=torch.long)\n","    batch_tags  = torch.tensor(batch_tags, dtype=torch.long)\n","    lengths = torch.tensor(lengths, dtype=torch.long)\n","\n","    return batch_words, batch_tags, lengths\n","\n","batch_size = 32\n","\n","train_dataset = PosDataset(train_sents, word2id, tag2id)\n","dev_dataset   = PosDataset(dev_sents, word2id, tag2id)\n","test_dataset  = PosDataset(test_sents, word2id, tag2id)\n","\n","train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True,\n","                          collate_fn=collate_fn)\n","dev_loader   = DataLoader(dev_dataset, batch_size=batch_size, shuffle=False,\n","                          collate_fn=collate_fn)\n","test_loader  = DataLoader(test_dataset, batch_size=batch_size, shuffle=False,\n","                          collate_fn=collate_fn)\n","\n","\n","# ---------------------------\n","# 4) BiLSTM model\n","# ---------------------------\n","class BiLSTMTagger(nn.Module):\n","    def __init__(self, vocab_size, tagset_size, emb_dim=128, hidden_dim=256, num_layers=1):\n","        super().__init__()\n","        self.embedding = nn.Embedding(vocab_size, emb_dim, padding_idx=pad_word_id)\n","        self.lstm = nn.LSTM(\n","            emb_dim,\n","            hidden_dim,\n","            num_layers=num_layers,\n","            batch_first=True,\n","            bidirectional=True,\n","        )\n","        self.fc = nn.Linear(hidden_dim * 2, tagset_size)\n","\n","    def forward(self, x, lengths):\n","        # x: (batch, seq_len)\n","        emb = self.embedding(x)  # (batch, seq_len, emb_dim)\n","\n","        # pack for efficient LSTM\n","        packed = nn.utils.rnn.pack_padded_sequence(\n","            emb, lengths.cpu(), batch_first=True, enforce_sorted=False\n","        )\n","        packed_out, _ = self.lstm(packed)\n","        lstm_out, _ = nn.utils.rnn.pad_packed_sequence(\n","            packed_out, batch_first=True\n","        )  # (batch, seq_len, hidden*2)\n","\n","        logits = self.fc(lstm_out)  # (batch, seq_len, num_tags)\n","        return logits\n","\n","model = BiLSTMTagger(vocab_size, num_tags).to(DEVICE)\n","criterion = nn.CrossEntropyLoss(ignore_index=pad_tag_id)\n","optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n","\n","\n","# ---------------------------\n","# 5) Training & eval functions\n","# ---------------------------\n","def train_epoch(model, loader):\n","    model.train()\n","    total_loss = 0.0\n","    for words, tags, lengths in loader:\n","        words = words.to(DEVICE)\n","        tags = tags.to(DEVICE)\n","        lengths = lengths.to(DEVICE)\n","\n","        optimizer.zero_grad()\n","        logits = model(words, lengths)  # (batch, seq_len, num_tags)\n","\n","        loss = criterion(\n","            logits.view(-1, num_tags),\n","            tags.view(-1)\n","        )\n","        loss.backward()\n","        optimizer.step()\n","\n","        total_loss += loss.item()\n","    return total_loss / len(loader)\n","\n","def eval_accuracy(model, loader):\n","    model.eval()\n","    correct = 0\n","    total = 0\n","    with torch.no_grad():\n","        for words, tags, lengths in loader:\n","            words = words.to(DEVICE)\n","            tags = tags.to(DEVICE)\n","            lengths = lengths.to(DEVICE)\n","\n","            logits = model(words, lengths)\n","            preds = logits.argmax(dim=-1)  # (batch, seq_len)\n","\n","            # compare while ignoring padding\n","            for p_seq, t_seq in zip(preds.cpu().numpy(), tags.cpu().numpy()):\n","                for p, t in zip(p_seq, t_seq):\n","                    if t == pad_tag_id:\n","                        continue\n","                    if p == t:\n","                        correct += 1\n","                    total += 1\n","    return correct / total if total > 0 else 0.0\n","\n","\n","# ---------------------------\n","# 6) Train loop\n","# ---------------------------\n","num_epochs = 5\n","\n","for epoch in range(1, num_epochs + 1):\n","    train_loss = train_epoch(model, train_loader)\n","    dev_acc = eval_accuracy(model, dev_loader)\n","    print(f\"Epoch {epoch}: train_loss={train_loss:.4f}, dev_acc={dev_acc:.4f}\")\n","\n","# Final test accuracy\n","test_acc = eval_accuracy(model, test_loader)\n","print(\"Test accuracy (BiLSTM):\", test_acc)\n","\n","\n","# ---------------------------\n","# 7) Predict on one sentence\n","# ---------------------------\n","def predict_sentence_bilstm(tokens):\n","    model.eval()\n","    w_ids = [word2id.get(w, unk_word_id) for w in tokens]\n","    length = torch.tensor([len(w_ids)], dtype=torch.long)\n","    x = torch.tensor([w_ids], dtype=torch.long)\n","    x = x.to(DEVICE)\n","    length = length.to(DEVICE)\n","\n","    with torch.no_grad():\n","        logits = model(x, length)\n","        preds = logits.argmax(dim=-1).cpu().numpy()[0]\n","\n","    tags = [id2tag[p] for p in preds[:len(tokens)]]\n","    return list(zip(tokens, tags))\n","\n","example = [\"سوريا\", \"تستقبل\", \"وفدا\", \"رسميا\", \".\"]\n","print(\"Example prediction:\", predict_sentence_bilstm(example))\n"]}]}